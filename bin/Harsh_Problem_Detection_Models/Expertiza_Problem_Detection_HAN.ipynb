{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Expertiza_Problem_Detection_HAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaBU0jP_kEvZ",
        "colab_type": "code",
        "outputId": "753d8778-67e1-45af-eaf2-f642bdec8c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqOBh_AskMWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp gdrive/My\\ Drive/AI-In-Peer-Assessment/suggestions_expertiza_fall2018_redone.csv ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSsq1XMAkOYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# To store data\n",
        "import pandas as pd\n",
        "\n",
        "# To use regular expressions\n",
        "import re\n",
        "\n",
        "#To load and save data\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8ORKH8DkQHy",
        "colab_type": "code",
        "outputId": "70ba5dd2-7bc7-4547-c412-121642fa2a9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ['KERAS_BACKEND']='tensorflow' # Or theano\n",
        "from keras import initializers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers as initializers, regularizers, constraints\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Layer\n",
        "\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "import json\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbaAWykokZrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = pd.read_csv(\"suggestions_expertiza_fall2018_redone.csv\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pLjd2VQkfws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_data = reviews.filter([\"REVIEW\",\"TAG\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5kYWH44NcVC",
        "colab_type": "code",
        "outputId": "27cf0fc1-2a62-4038-96c5-97f66dbe7fa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "new_data.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Suggest_Solutions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Of what code is available in the zip file, mos...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Though not much \"hand writed\" but still great ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Github link is not submitted. I downloaded the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Not uploaded on git.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>There is no Github link provided. Instead the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments  Suggest_Solutions\n",
              "0  Of what code is available in the zip file, mos...                  0\n",
              "1  Though not much \"hand writed\" but still great ...                  0\n",
              "2  Github link is not submitted. I downloaded the...                  0\n",
              "3                               Not uploaded on git.                  0\n",
              "4  There is no Github link provided. Instead the ...                  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMKvL5v6khdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_data = new_data.loc[new_data.REVIEW.apply(lambda x: not isinstance(x, (float, int)))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHKsxphkk7K",
        "colab_type": "code",
        "outputId": "11e2208d-84fb-4265-c704-d4d666f7990e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "new_data['TAG'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1939\n",
              "0    1939\n",
              "Name: Suggest_Solutions, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xY1RF2ZknOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set, test_set = train_test_split(new_data, test_size=0.05, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLRXcXMikoe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_reviews = list(train_set[\"REVIEW\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_Wgd7tDkqvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = list(train_set[\"TAG\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEIe_Gvmkswx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(train_reviews)):\n",
        "  train_reviews[i] = re.sub('\\d',' ',train_reviews[i]) # Replacing digits by space\n",
        "  train_reviews[i] = re.sub(r'\\s+[a-z][\\s$]', ' ',train_reviews[i]) # Removing single characters and spaces alongside\n",
        "  train_reviews[i] = re.sub(r'\\s+', ' ',train_reviews[i]) # Replacing more than one space with a single space"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8o7E1pVku47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(train_reviews)):\n",
        "    if 'www.' in train_reviews[i] or 'http:' in train_reviews[i] or 'https:' in train_reviews[i] or '.com' in train_reviews[i]:\n",
        "        train_reviews[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", train_reviews[i])\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1fbpxmuk6fn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training model only on a subset of data\n",
        "from sklearn.utils import shuffle\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "x, y = shuffle(train_reviews, train_labels)\n",
        "\n",
        "#Backup\n",
        "train_x = train_reviews\n",
        "train_y = train_labels\n",
        "\n",
        "review_len = 0\n",
        "sentence_len = 0\n",
        "\n",
        "for review  in x:\n",
        "    sentences = review.split(\".\")\n",
        "    review_len += len(sentences)\n",
        "    for sentence in sentences:\n",
        "        sentence_len += len(text_to_word_sequence(sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiGQIJghlLzT",
        "colab_type": "code",
        "outputId": "1293e564-711e-467e-9f6f-d5ed293f599c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Based on output set max sentence amd max sentense length variables below\n",
        "print(int(review_len/ len(train_reviews)))\n",
        "print(int(sentence_len / len(train_reviews)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOP-XAqfkzDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SENTENCES = 3 # Maximum number of sentences to be considered as a review for each sample\n",
        "MAX_SENTENCE_LENGTH = 33 # Maximum number of words to be considered as a sentence for each sample\n",
        "MAX_NB_WORDS = 800 # This specifies how many top tokens in each review to be stored\n",
        "EMBEDDING_DIM = 100\n",
        "MAX_SEQUENCE_LENGTH = 100 # Padding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTU9TIemlmB0",
        "colab_type": "code",
        "outputId": "edb8d491-4d9d-48d8-a4a3-b56ddd99f0ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# Takes 5 minutes to run on entire training dataset\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(train_reviews)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_reviews)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Number of Unique Tokens',len(word_index)) # Total 996497 unique words "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Unique Tokens 5319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnzEJsnnmI6Y",
        "colab_type": "code",
        "outputId": "e139f79b-ba03-46a5-bb75-76ab807dfa54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#Padding\n",
        "#train_x = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "#type(train_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ66-bjKmLis",
        "colab_type": "code",
        "outputId": "db26ae07-2894-45f8-9c5c-224be652fd2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!cp gdrive/My\\ Drive/glove100d.zip .\n",
        "!unzip glove100d.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove100d.zip\n",
            "  inflating: glove.6B.100d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45BgLMUOmNi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = {}\n",
        "for i, line in enumerate(open('glove.6B.100d.txt')):\n",
        "  values = line.split() # 0 th index will be the word and rest will the embedding vector (size 100 as we have used Glove.6B.100D embedding file) \n",
        "  embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdQ2kKg_mPdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create token(words in word index)-embedding mapping\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, 100)) # 100 since embedding_dimesion is 100, +1 because index 0 is reserved in word_index\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "# We can initialize random vector and assign for words which are not present in embeddings.Other option is keep trainable=true in embedding layer of the NN model.\n",
        "# We choose 2nd option"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfw5M7cfmRxu",
        "colab_type": "code",
        "outputId": "20c6883f-051f-4c91-fed9-cd9d11526612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "nonzero_elements = np.count_nonzero(np.count_nonzero(embedding_matrix, axis=1))\n",
        "nonzero_elements / len(word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7497649934198157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBJt1Ar6mX_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hJQBc3Nwhj96",
        "colab": {}
      },
      "source": [
        "data = np.zeros((len(train_x), MAX_SENTENCES, MAX_SENTENCE_LENGTH))\n",
        "\n",
        "for i, review in enumerate(train_x):\n",
        "    sentences = review.split(\".\")\n",
        "    for j, sentence in enumerate(sentences):\n",
        "    # Number of sentences should be less than the maximum\n",
        "        if j < MAX_SENTENCES:            \n",
        "            wordTokens = text_to_word_sequence(sentence)\n",
        "            k = 0\n",
        "            for word in wordTokens:\n",
        "                if k < MAX_SENTENCE_LENGTH and word_index[word] < MAX_NB_WORDS:\n",
        "                    data[i, j, k] = word_index[word]\n",
        "                    k += 1\n",
        "train_x = data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHIgiLhSmfxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Attention Layer\n",
        "def dot_product(x, kernel):\n",
        "\n",
        "    if K.backend() == 'tensorflow':\n",
        "        # todo: check that this is correct\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "\n",
        "\n",
        "class Attention(Layer):\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True,\n",
        "                 return_attention=False,\n",
        "                 **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.return_attention = return_attention\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        eij = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        weighted_input = x * K.expand_dims(a)\n",
        "\n",
        "        result = K.sum(weighted_input, axis=1)\n",
        "\n",
        "        if self.return_attention:\n",
        "            return [result, a]\n",
        "        return result\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.return_attention:\n",
        "            return [(input_shape[0], input_shape[-1]),\n",
        "                    (input_shape[0], input_shape[1])]\n",
        "        else:\n",
        "            return input_shape[0], input_shape[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZTx5K-cmik5",
        "colab_type": "code",
        "outputId": "97c0117c-9f0f-42bf-e78e-337028d6c720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Model architecture\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,weights=[embedding_matrix],\n",
        "                            input_length=MAX_SENTENCE_LENGTH,trainable=True)\n",
        "\n",
        "# Words level attention model\n",
        "word_input = Input(shape=(MAX_SENTENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(word_input)\n",
        "word_lstm = Bidirectional(GRU(64, return_sequences=True,recurrent_dropout=0.5))(embedded_sequences)\n",
        "word_att = Attention()(word_lstm)\n",
        "word_drp = Dropout(0.4)(word_att)\n",
        "wordEncoder = Model(word_input, word_drp)\n",
        "\n",
        "# Sentence level attention model\n",
        "sent_input = Input(shape=(MAX_SENTENCES, MAX_SENTENCE_LENGTH), dtype='int32')\n",
        "sent_encoder = TimeDistributed(wordEncoder)(sent_input)\n",
        "sent_lstm = Bidirectional(GRU(64, return_sequences=True, recurrent_dropout = 0.5))(sent_encoder)\n",
        "sent_att = Attention()(sent_lstm)\n",
        "sent_drp = Dropout(0.5)(sent_att)\n",
        "preds = Dense(1, activation='sigmoid')(sent_drp)\n",
        "model = Model(sent_input, preds)\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "# Keeping a checkpoint to store only the model which gives best output validation accuracy\n",
        "chkpt=ModelCheckpoint('expertiza_han_model.h5',monitor='val_acc',verbose=1,save_best_only=True)\n",
        "\n",
        "model_history = model.fit(train_x, train_y, batch_size=256, epochs=15, validation_split=0.2,callbacks=[chkpt])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 3, 33)             0         \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 3, 128)            595521    \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 3, 128)            74112     \n",
            "_________________________________________________________________\n",
            "attention_4 (Attention)      (None, 128)               131       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 669,893\n",
            "Trainable params: 669,893\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 2947 samples, validate on 737 samples\n",
            "Epoch 1/10\n",
            "2947/2947 [==============================] - 12s 4ms/step - loss: 0.6256 - acc: 0.6318 - val_loss: 0.5402 - val_acc: 0.7463\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.74627, saving model to expertiza_han_model.h5\n",
            "Epoch 2/10\n",
            "2947/2947 [==============================] - 8s 3ms/step - loss: 0.5215 - acc: 0.7472 - val_loss: 0.4269 - val_acc: 0.8223\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.74627 to 0.82225, saving model to expertiza_han_model.h5\n",
            "Epoch 3/10\n",
            "2947/2947 [==============================] - 8s 3ms/step - loss: 0.4606 - acc: 0.7947 - val_loss: 0.3517 - val_acc: 0.8548\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.82225 to 0.85482, saving model to expertiza_han_model.h5\n",
            "Epoch 4/10\n",
            "2947/2947 [==============================] - 8s 3ms/step - loss: 0.3718 - acc: 0.8446 - val_loss: 0.2940 - val_acc: 0.8792\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.85482 to 0.87924, saving model to expertiza_han_model.h5\n",
            "Epoch 5/10\n",
            "2947/2947 [==============================] - 8s 3ms/step - loss: 0.3391 - acc: 0.8619 - val_loss: 0.2879 - val_acc: 0.8874\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.87924 to 0.88738, saving model to expertiza_han_model.h5\n",
            "Epoch 6/10\n",
            "2947/2947 [==============================] - 8s 3ms/step - loss: 0.2998 - acc: 0.8775 - val_loss: 0.2816 - val_acc: 0.8806\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.88738\n",
            "Epoch 7/10\n",
            "2947/2947 [==============================] - 8s 3ms/step - loss: 0.2915 - acc: 0.8867 - val_loss: 0.2799 - val_acc: 0.8820\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.88738\n",
            "Epoch 8/10\n",
            "2947/2947 [==============================] - 8s 3ms/step - loss: 0.2703 - acc: 0.8979 - val_loss: 0.2841 - val_acc: 0.8752\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.88738\n",
            "Epoch 9/10\n",
            "2947/2947 [==============================] - 8s 3ms/step - loss: 0.2704 - acc: 0.8972 - val_loss: 0.3172 - val_acc: 0.8874\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.88738 to 0.88738, saving model to expertiza_han_model.h5\n",
            "Epoch 10/10\n",
            "2947/2947 [==============================] - 8s 3ms/step - loss: 0.2369 - acc: 0.9084 - val_loss: 0.2795 - val_acc: 0.8847\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.88738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXwQt6Tii0yD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving the model so that it can be loaded easily again\n",
        "model.save_weights('expertiza_han_model_weights.h5')\n",
        "\n",
        "# Save the model architecture\n",
        "with open('expertiza_han_model_architecture.json', 'w') as f:\n",
        "    f.write(model.to_json())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YGyYqN3i4Yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Persisting model weights\n",
        "!cp expertiza_han_model_weights.h5 gdrive/My\\ Drive/AI-In-Peer-Assessment/model/\n",
        "# Persisting model architecture\n",
        "!cp expertiza_han_model_architecture.json gdrive/My\\ Drive/AI-In-Peer-Assessment/model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNxD8PAkjAvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}